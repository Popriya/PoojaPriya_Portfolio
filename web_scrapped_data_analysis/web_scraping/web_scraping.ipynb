{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Selenium package- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "from   scipy   import   stats\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(r'https://www.linkedin.com/jobs/search?location=United%20States&geoId=103644278&locationId=&keywords=Data%20Analyst&f_TPR=r86400&trk=homepage-jobseeker_recent-search&position=1&pageNum=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_csv_file_path= \"./job_csv/\"\n",
    "if not os.path.isdir(job_csv_file_path):\n",
    "    os.mkdir(job_csv_file_path)\n",
    "SLEEP_TIME = 5\n",
    "chromedriver_exe = input(\"Provide path to the chromedriver executable\")\n",
    "browser = webdriver.Chrome(executable_path=chromedriver_exe)\n",
    "browser.get(url)\n",
    "i = 0\n",
    "APPROX_MAX_COUNT = 100\n",
    "count = 0\n",
    "f_cnt = 0\n",
    "while(count < APPROX_MAX_COUNT):\n",
    "    try:\n",
    "        browser.find_element_by_xpath(\"/html/body/div[1]/div/main/section[2]/button\").click()\n",
    "        time.sleep(SLEEP_TIME)\n",
    "    except:\n",
    "        pass\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    try:\n",
    "        ul = browser.find_element_by_xpath(\"/html/body/div[1]/div/main/section[2]/ul\")\n",
    "        job_links = ul.find_elements_by_tag_name(\"li\")\n",
    "    except:\n",
    "        pass\n",
    "    curr_count = count\n",
    "    job_list=[]\n",
    "    for job_link in job_links[curr_count:]:\n",
    "        if count > APPROX_MAX_COUNT:\n",
    "            break\n",
    "        job_data = {}\n",
    "        #print(job_link)\n",
    "        job_link.click()\n",
    "        time.sleep(SLEEP_TIME)\n",
    "        page = soup(browser.page_source,'lxml')\n",
    "        try:\n",
    "            job_data['job_title'] =page.find('h2',{'class':'top-card-layout__title'})\n",
    "            job_data['company_name'] = page.find('span',{'class':'topcard__flavor'})\n",
    "            job_data['location'] = page.find('span',{'class':'topcard__flavor topcard__flavor--bullet'})\n",
    "            job_data['post_time'] = page.find('span',{'class':'posted-time-ago__text posted-time-ago__text--new topcard__flavor--metadata'})\n",
    "            job_data['applicant_count'] = page.find('span',{'class':'num-applicants__caption topcard__flavor--metadata topcard__flavor--bullet'})\n",
    "            #job_data['summary'] = page.find('div',{'class':'show-more-less-html__markup'})\n",
    "            job_data['salary'] = page.find(\"div\",{\"class\":\"salary compensation__salary\"})\n",
    "            job_criteria_ul = page.find('ul',{'class':'description__job-criteria-list'})\n",
    "            job_criterion_list = job_criteria_ul.find_all('li')\n",
    "            for job_criteria in job_criterion_list:\n",
    "                job_criteria_field = job_criteria.find('h3',{'class':\"description__job-criteria-subheader\"})\n",
    "                job_criteria_value = job_criteria\\\n",
    "                .find('span',{'class':\"description__job-criteria-text description__job-criteria-text--criteria\"})\n",
    "                job_data[job_criteria_field.get_text().strip()] = job_criteria_value\n",
    "            for k,v in job_data.items():\n",
    "                if v:\n",
    "                    job_data[k] = v.get_text().strip()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            print(e)\n",
    "            time.sleep(SLEEP_TIME)\n",
    "        job_list.append(job_data)\n",
    "        count+=1\n",
    "    if job_list:\n",
    "        df = pd.DataFrame(job_list)\n",
    "        csv_path = f\"{job_csv_file_path}/{f_cnt}.csv\"\n",
    "        f_cnt+=1\n",
    "        df.to_csv(csv_path,index=False)\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for f in os.listdir(job_csv_file_path):\n",
    "    file_name = f\"{job_csv_file_path}/{f}\"\n",
    "    #print(file_name)\n",
    "    df_temp = pd.read_csv(file_name)\n",
    "    df = pd.concat([df,df_temp],ignore_index=True, sort=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.drop_duplicates(df)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean locations\n",
    "def split_location(e):\n",
    "    us = set([\"US\",\"United States\"])\n",
    "    s_list = e.split(\",\")\n",
    "    if len(s_list)==2 and not any([(s.strip() in us) for s in s_list]):\n",
    "        return e\n",
    "    else:\n",
    "        return \"Not Applicable,Not Applicable\"\n",
    "city_state = df[\"location\"].apply(split_location)\n",
    "city_state_df = city_state.str.split(pat=\",\",expand=True)\n",
    "df[\"city\"],df[\"state\"] = city_state_df[0],city_state_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean post time\n",
    "def post_time_to_days(e):\n",
    "    hour_set = set([\"hours\",\"hour\"])\n",
    "    day_set = set([\"days\",\"day\"])\n",
    "    week_set = set([\"week\",\"weeks\"])\n",
    "    month_set = set([\"month\",\"months\"])\n",
    "    if type(e) is str:\n",
    "        count,unit,rest =  e.split()\n",
    "        if unit.lower() in hour_set:\n",
    "            return f'{(int(count)/24):.2f}'\n",
    "        elif unit.lower() in day_set:\n",
    "            return count\n",
    "        elif unit.lower() in week_set:\n",
    "            return str(int(count)*7)\n",
    "        elif unit.lower() in month_set:\n",
    "            return str(int(count)*30)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "df[\"posted_days\"] = df[\"post_time\"].apply(post_time_to_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert applicants to int\n",
    "df[\"applicant_count_int\"] =  df[\"applicant_count\"].str.split(expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(platform.node())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyodbc.drivers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy \n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import socket\n",
    "\n",
    "conn = sqlalchemy.create_engine(f'mssql+pyodbc://{socket.gethostname()}/Test?trusted_connection=yes&driver=ODBC Driver 17 for SQL Server')\n",
    "#df = pd.read_csv(\"./data.csv\")\n",
    "\n",
    "# quoted = urllib.parse.quote_plus(\"DRIVER={SQL Server Native Client 11.0};SERVER=(localhost,1433);DATABASE=Portfolio\")\n",
    "# engine = create_engine('mssql+pyodbc:///?odbc_connect={}'.format(quoted))\n",
    "\n",
    "df.to_sql('JobData',con = conn,if_exists= 'append', index = False)\n",
    "\n",
    "# result = engine.execute('SELECT COUNT(*) FROM [dbo].[JobDataTable]')\n",
    "# result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER=localhost.com:1433;DATABASE=Portfolio;Trusted_Connection=yes;')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwd = input(\"Enter password for SQL db\")\n",
    "conn = pymssql.connect(\n",
    "    host=r'localhost',\n",
    "    user=r'sa',\n",
    "    password=passwd,\n",
    "    database='Portfolio'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor(as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * from JobData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cursor.fetchall()\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import event\n",
    "@event.listens_for(engine, \"before_cursor_execute\")\n",
    "def receive_before_cursor_execute(\n",
    "       conn, cursor, statement, params, context, executemany\n",
    "        ):\n",
    "            if executemany:\n",
    "                cursor.fast_executemany = True\n",
    "                \n",
    "df.to_sql(JobData, engine, index=False, if_exists=\"append\", schema=\"dbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = ''\n",
    "server = 'localhost'\n",
    "database = 'Portfolio'\n",
    "username = 'sa'\n",
    "params = 'DRIVER='+driver + ';SERVER='+server + ';PORT=1433;DATABASE=' + database + ';UID=' + username + ';PWD=' + passwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyodbc.drivers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
